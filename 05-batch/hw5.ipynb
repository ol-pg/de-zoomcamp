{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00bc6543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd4a0f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/04 20:14:03 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6861dab4",
   "metadata": {},
   "source": [
    "### Question 1. Spark version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb3e4c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d43c11",
   "metadata": {},
   "source": [
    "### Question 2. FHV October 2019 partition size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af81bf96",
   "metadata": {},
   "source": [
    "Read the October 2019 FHV into a Spark Dataframe with a schema as we did in the lessons.\n",
    "\n",
    "Repartition the Dataframe to 6 partitions and save it to parquet.\n",
    "\n",
    "What is the average size of the Parquet (ending with .parquet extension) Files that were created (in MB)? Select the answer which most closely matches.\n",
    "- 1MB\n",
    "- **6MB**\n",
    "- 25MB\n",
    "- 87MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ab331e81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-04 20:25:09--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240304%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240304T202509Z&X-Amz-Expires=300&X-Amz-Signature=0ef79967bb8add4912899e1091f1103f656af6c541eb9391d39adbe9efb50907&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-03-04 20:25:10--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/efdfcf82-6d5c-44d1-a138-4e8ea3c3a3b6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240304%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240304T202509Z&X-Amz-Expires=300&X-Amz-Signature=0ef79967bb8add4912899e1091f1103f656af6c541eb9391d39adbe9efb50907&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dfhv_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 19375751 (18M) [application/octet-stream]\n",
      "Saving to: ‘fhv_tripdata_2019-10.csv.gz’\n",
      "\n",
      "fhv_tripdata_2019-1 100%[===================>]  18.48M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2024-03-04 20:25:10 (177 MB/s) - ‘fhv_tripdata_2019-10.csv.gz’ saved [19375751/19375751]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-10.csv.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "68c0415c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        dispatching_base_num      pickup_datetime     dropOff_datetime  \\\n",
      "0                     B00009  2019-10-01 00:23:00  2019-10-01 00:35:00   \n",
      "1                     B00013  2019-10-01 00:11:29  2019-10-01 00:13:22   \n",
      "2                     B00014  2019-10-01 00:11:43  2019-10-01 00:37:20   \n",
      "3                     B00014  2019-10-01 00:56:29  2019-10-01 00:57:47   \n",
      "4                     B00014  2019-10-01 00:23:09  2019-10-01 00:28:27   \n",
      "...                      ...                  ...                  ...   \n",
      "1897488               B03160  2019-10-31 23:38:00  2019-10-31 23:48:00   \n",
      "1897489               B03160  2019-10-31 23:11:00  2019-10-31 23:43:00   \n",
      "1897490               B03160  2019-10-31 23:13:00  2019-10-31 23:41:00   \n",
      "1897491               B03186  2019-10-31 23:02:32  2019-10-31 23:09:53   \n",
      "1897492               B03186  2019-10-31 23:19:24  2019-10-31 23:24:31   \n",
      "\n",
      "         PUlocationID  DOlocationID  SR_Flag Affiliated_base_number  \n",
      "0               264.0         264.0      NaN                 B00009  \n",
      "1               264.0         264.0      NaN                 B00013  \n",
      "2               264.0         264.0      NaN                 B00014  \n",
      "3               264.0         264.0      NaN                 B00014  \n",
      "4               264.0         264.0      NaN                 B00014  \n",
      "...               ...           ...      ...                    ...  \n",
      "1897488         242.0          81.0      NaN                 B02887  \n",
      "1897489         161.0          28.0      NaN                 B02883  \n",
      "1897490         168.0         215.0      NaN                 B02883  \n",
      "1897491         264.0         119.0      NaN                 B03186  \n",
      "1897492         264.0         119.0      NaN                 B03186  \n",
      "\n",
      "[1897493 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('fhv_tripdata_2019-10.csv.gz',compression='gzip')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0a3399a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True),\n",
    "    types.StructField('dropoff_datetime', types.TimestampType(), True),\n",
    "    types.StructField('PULocationID', types.IntegerType(), True),\n",
    "    types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "    types.StructField('SR_Flag', types.StringType(), True),\n",
    "    types.StructField('Affiliated_base_number', types.StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "68bc8b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('fhv_tripdata_2019-10.csv.gz', sep=',')\n",
    "\n",
    "df = df.repartition(6)\n",
    "\n",
    "df.write.parquet('fhv/2019/10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "46eca068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 39M\r\n",
      "-rw-r--r-- 1 olga olga    0 Mar  4 20:38 _SUCCESS\r\n",
      "-rw-r--r-- 1 olga olga 6.4M Mar  4 20:38 part-00000-5aec6f27-98a0-46dc-935c-382b02350165-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 olga olga 6.4M Mar  4 20:38 part-00001-5aec6f27-98a0-46dc-935c-382b02350165-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 olga olga 6.4M Mar  4 20:38 part-00002-5aec6f27-98a0-46dc-935c-382b02350165-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 olga olga 6.4M Mar  4 20:38 part-00003-5aec6f27-98a0-46dc-935c-382b02350165-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 olga olga 6.4M Mar  4 20:38 part-00004-5aec6f27-98a0-46dc-935c-382b02350165-c000.snappy.parquet\r\n",
      "-rw-r--r-- 1 olga olga 6.4M Mar  4 20:38 part-00005-5aec6f27-98a0-46dc-935c-382b02350165-c000.snappy.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lh fhv/2019/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "58989b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('fhv/2019/10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0df00f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6daa85b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|Affiliated_base_number|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "|              B02784|2019-10-01 09:55:38|2019-10-01 10:05:43|          89|          85|   null|                  null|\n",
      "|              B02429|2019-10-21 04:15:47|2019-10-21 04:36:04|         264|         264|   null|                B02429|\n",
      "|              B01482|2019-10-19 12:00:00|2019-10-19 12:20:00|         264|         264|   null|                B01482|\n",
      "|              B03015|2019-10-11 14:28:00|2019-10-11 14:32:44|         264|         216|   null|                B03015|\n",
      "|              B01529|2019-10-21 18:00:26|2019-10-21 18:07:21|         264|          80|   null|                B01529|\n",
      "|              B00477|2019-10-03 19:30:35|2019-10-03 20:27:57|         161|          14|   null|                B00477|\n",
      "|              B00937|2019-10-25 06:10:40|2019-10-25 06:29:43|         264|         208|   null|                B00937|\n",
      "|     B00889         |2019-10-30 06:18:02|2019-10-30 06:35:12|         260|         260|   null|       B00889         |\n",
      "|              B01239|2019-10-09 03:39:16|2019-10-09 03:42:07|         264|         254|   null|                B00882|\n",
      "|              B00256|2019-10-27 11:54:37|2019-10-27 12:28:18|         264|         264|   null|                B00256|\n",
      "|              B01087|2019-10-14 18:41:24|2019-10-14 19:02:06|         261|         186|   null|                B01087|\n",
      "|              B02846|2019-10-19 11:42:45|2019-10-19 12:42:42|         264|          23|   null|                B02846|\n",
      "|              B02546|2019-10-17 15:20:32|2019-10-17 15:25:51|         264|         167|   null|                B02546|\n",
      "|              B02803|2019-10-21 05:00:47|2019-10-21 05:03:44|          47|         169|   null|                B02803|\n",
      "|              B01644|2019-10-14 11:34:00|2019-10-14 13:12:00|         264|         264|   null|                B01644|\n",
      "|              B01454|2019-10-13 07:08:41|2019-10-13 07:13:43|         264|         188|   null|                B01454|\n",
      "|              B01239|2019-10-24 06:05:22|2019-10-24 06:15:03|         264|         174|   null|                B00882|\n",
      "|              B01751|2019-10-20 09:49:18|2019-10-20 10:40:59|         264|         264|   null|                B01751|\n",
      "|              B00887|2019-10-06 17:17:28|2019-10-06 18:12:14|         264|         132|   null|                B00887|\n",
      "|              B01362|2019-10-07 11:25:57|2019-10-07 11:39:15|         264|         185|   null|                B01362|\n",
      "+--------------------+-------------------+-------------------+------------+------------+-------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b01d2f",
   "metadata": {},
   "source": [
    "### Question 3. Count records on 15th of October\n",
    "Count records\n",
    "\n",
    "How many taxi trips were there on the 15th of October?\n",
    "\n",
    "Consider only trips that started on the 15th of October.\n",
    "- 108,164\n",
    "- 12,856\n",
    "- 452,470\n",
    "- **62,610**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f7489aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6c2500fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62610"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .filter(\"pickup_date = '2019-10-15'\") \\\n",
    "    .count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dd7ae60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.registerTempTable('fhv_2019_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6d47c147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|   62610|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    COUNT(1)\n",
    "FROM \n",
    "    fhv_2019_10\n",
    "WHERE\n",
    "    to_date(pickup_datetime) = '2019-10-15';\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3f533b",
   "metadata": {},
   "source": [
    "### Question 4. The longest trip\n",
    "\n",
    "Longest trip for each day\n",
    "\n",
    "What is the length of the longest trip in the dataset in hours?\n",
    "- **631,152.50 Hours**\n",
    "- 243.44 Hours\n",
    "- 7.68 Hours\n",
    "- 3.32 Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7befe422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dispatching_base_num',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'SR_Flag',\n",
       " 'Affiliated_base_number']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bec239d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Time difference in Hours\n",
    "hour_dur=df.withColumn('pickup_datetime',F.unix_timestamp(F.col('pickup_datetime')))\\\n",
    "  .withColumn('dropoff_datetime',F.unix_timestamp(F.col('dropoff_datetime')))\\\n",
    "  .withColumn('diff_in_hours',(F.col(\"dropoff_datetime\") - F.col('pickup_datetime'))/3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b55e5a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e18cb5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|max(diff_in_hours)|\n",
      "+------------------+\n",
      "|          631152.5|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hour_dur.select(max(hour_dur.diff_in_hours)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d915096b",
   "metadata": {},
   "source": [
    "### Question 5. Spark UI port\n",
    "\n",
    "User Interface\n",
    "\n",
    "Spark’s User Interface which shows the application's dashboard runs on which local port?\n",
    "\n",
    "- 80\n",
    "- 443\n",
    "- **4040**\n",
    "- 8080"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d10173a",
   "metadata": {},
   "source": [
    "###  Question 6. Least frequent pickup location zone\n",
    "Least frequent pickup location zone\n",
    "\n",
    "Using the zone lookup data and the FHV October 2019 data, what is the name of the LEAST frequent pickup location Zone?\n",
    "\n",
    "- East Chelsea\n",
    "- **Jamaica Bay**\n",
    "- Union Sq\n",
    "- Crown Heights North"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "370d6182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-04 20:46:14--  https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.117.112, 52.216.213.120, 52.216.52.0, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.117.112|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi+_zone_lookup.csv’\n",
      "\n",
      "taxi+_zone_lookup.c 100%[===================>]  12.03K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-03-04 20:46:14 (110 MB/s) - ‘taxi+_zone_lookup.csv’ saved [12322/12322]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2b61f5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('taxi+_zone_lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "81642d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LocationID', 'Borough', 'Zone', 'service_zone']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4f460dda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dispatching_base_num',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'SR_Flag',\n",
       " 'Affiliated_base_number']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ad8f0101",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones.createOrReplaceTempView('zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6f738414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|                Zone|cnt|\n",
      "+--------------------+---+\n",
      "|Governor's Island...|  4|\n",
      "|       Rikers Island|  4|\n",
      "|         Jamaica Bay| 14|\n",
      "|        Battery Park| 35|\n",
      "|       Broad Channel| 36|\n",
      "|Breezy Point/Fort...| 54|\n",
      "|        Astoria Park| 73|\n",
      "|     Freshkills Park|132|\n",
      "|Saint Michaels Ce...|162|\n",
      "| Green-Wood Cemetery|261|\n",
      "|       Willets Point|301|\n",
      "|     Columbia Street|321|\n",
      "|Marine Park/Floyd...|339|\n",
      "|    Roosevelt Island|348|\n",
      "|         City Island|389|\n",
      "|     Cambria Heights|404|\n",
      "|     Randalls Island|404|\n",
      "|       Rockaway Park|412|\n",
      "|  Brooklyn Navy Yard|455|\n",
      "|Stuy Town/Peter C...|466|\n",
      "+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT\n",
    "    zones.Zone,\n",
    "    COUNT(*) cnt\n",
    "FROM \n",
    "    fhv_2019_10,zones \n",
    "where fhv_2019_10.DOLocationID = zones.LocationID\n",
    "GROUP BY zones.Zone\n",
    "ORDER BY cnt ASC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b754d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
